{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# TAKEN DIRECTLY FROM HUGGING FACE\n",
    "#CheXagent 8b \n",
    "#You need state-of-the-art performance across multiple clinical tasks\n",
    "#You’re working with larger datasets or want to use CheXbench for evaluation\n",
    "#You’re okay with higher compute requirements\n",
    "#You want to generate full radiology reports, not just binary answers\n",
    "########\n",
    "\n",
    "import io\n",
    "\n",
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor, GenerationConfig\n",
    "\n",
    "# step 1: Setup constant\n",
    "device = \"cuda\"\n",
    "dtype = torch.float16\n",
    "\n",
    "# step 2: Load Processor and Model\n",
    "processor = AutoProcessor.from_pretrained(\"StanfordAIMI/CheXagent-8b\", trust_remote_code=True)\n",
    "generation_config = GenerationConfig.from_pretrained(\"StanfordAIMI/CheXagent-8b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"StanfordAIMI/CheXagent-8b\", torch_dtype=dtype, trust_remote_code=True)\n",
    "\n",
    "# step 3: Fetch the images\n",
    "image_path = \"https://upload.wikimedia.org/wikipedia/commons/3/3b/Pleural_effusion-Metastatic_breast_carcinoma_Case_166_%285477628658%29.jpg\"\n",
    "images = [Image.open(io.BytesIO(requests.get(image_path).content)).convert(\"RGB\")]\n",
    "\n",
    "# step 4: Generate the Findings section\n",
    "prompt = f'Describe \"Airway\"'\n",
    "inputs = processor(images=images, text=f\" USER: <s>{prompt} ASSISTANT: <s>\", return_tensors=\"pt\").to(device=device, dtype=dtype)\n",
    "output = model.generate(**inputs, generation_config=generation_config)[0]\n",
    "response = processor.tokenizer.decode(output, skip_special_tokens=True)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
