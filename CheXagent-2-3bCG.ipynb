{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "id": "0",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1",
    "outputId": "bc078ba1-4031-4ee3-96cb-393b1afd63d4",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip -q install \"transformers>=4.41\" peft bitsandbytes accelerate datasets sentencepiece einops pydicom pillow\n",
    "\n",
    "import os, re, shutil, math, random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM,\n",
    "    TrainingArguments, Trainer\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "id": "2",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "####Mount the drive\n",
    "################ attach the colab project to the google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "from pathlib import Path\n",
    "ROOT        = Path('/content/drive/MyDrive/MLProjects/foundation-models-radiology')\n",
    "DICOM_DIR   = ROOT / 'PTXHeadtoHeadSmall'   # use the exact folder name as on Drive\n",
    "IMG_DIR     = ROOT / \"chex_jpg\"                   # where we'll write JPEGs\n",
    "CSV_PATH    = ROOT / \"labels_200.csv\"             # your instruction CSV (image,question,answer)\n",
    "\n",
    "print(\"exists:\", DICOM_DIR.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "id": "45NwAUwr8dbV"
   },
   "outputs": [],
   "source": [
    "################ Global variables\n",
    "MODEL_NAME = \"StanfordAIMI/CheXagent-2-3b\"\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "id": "fnmTlacT9Tz8"
   },
   "outputs": [],
   "source": [
    "#########DICOM to grayscale\n",
    "shutil.rmtree(IMG_DIR, ignore_errors=True)\n",
    "IMG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def dicom_to_jpg(dcm_path: Path, out_dir: Path) -> Path:\n",
    "    ds = pydicom.dcmread(str(dcm_path), stop_before_pixels=False)\n",
    "    arr = ds.pixel_array\n",
    "\n",
    "    # Respect VOI LUT (windowing) when present\n",
    "    try:\n",
    "        arr = apply_voi_lut(arr, ds)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Fix MONOCHROME1 inversion\n",
    "    if getattr(ds, \"PhotometricInterpretation\", \"\") == \"MONOCHROME1\":\n",
    "        arr = np.max(arr) - arr\n",
    "\n",
    "    arr = arr.astype(np.float32)\n",
    "    arr -= arr.min()\n",
    "    if arr.max() > 0:\n",
    "        arr /= arr.max()\n",
    "    arr = (arr * 255.0).clip(0,255).astype(np.uint8)\n",
    "\n",
    "    # Optional: resize to something reasonable (e.g., 1024px max side)\n",
    "    h, w = arr.shape[:2]\n",
    "    max_side = 1024\n",
    "    if max(h,w) > max_side:\n",
    "        scale = max_side / max(h,w)\n",
    "        arr = np.array(Image.fromarray(arr).resize((int(w*scale), int(h*scale)), Image.LANCZOS))\n",
    "\n",
    "    img = Image.fromarray(arr, mode=\"L\")\n",
    "    out_path = out_dir / (dcm_path.stem + \".jpg\")\n",
    "    img.save(out_path, quality=95)\n",
    "    return out_path\n",
    "\n",
    "# find dicoms, convert first ~200\n",
    "dcm_paths = list(DICOM_DIR.rglob(\"*.[dD][cC][mM]\"))\n",
    "dcm_paths = dcm_paths[:200] if len(dcm_paths) > 200 else dcm_paths\n",
    "jpg_paths = [dicom_to_jpg(p, IMG_DIR) for p in dcm_paths]\n",
    "len(jpg_paths), jpg_paths[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "id": "nsZczvJ19KRv"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# step 1: Setup constant\n",
    "model_name = \"StanfordAIMI/CheXagent-2-3b\"\n",
    "dtype = torch.bfloat16\n",
    "device = \"cuda\"\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
